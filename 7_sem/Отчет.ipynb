{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img style=\"float:left;\" src=\"/home/jzadorozhnaya/Supercomputers_msu/7_sem/Report/vmk.png\" width=\"12%\">\n",
    "    <img style=\"float:right;margin-top:0px;\" src=\"/home/jzadorozhnaya/Supercomputers_msu/7_sem/Report/msu.png\" width=\"12%\">\n",
    "    <div style=\"margin-top:25px;text-align:center;font-size:25px\">МОСКОВСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ</div>\n",
    "    <div style=\"margin-top:35px;text-align:center;font-size:18px\">имени М.В. Ломоносова</div>\n",
    "    <div style=\"margin-top:25px;text-align:center;font-size:25px\">Факультет вычислительной математики и кибернетики</div>\n",
    "    <br><br><br><br><br><br><br><br>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><div style=\"text-align:center;font-size:40px\">Практикум по курсу</div>\n",
    "<strong><div style=\"margin-top:30px;text-align:center;font-size:30px\">\"Распределённые системы\"</div>\n",
    "<strong><div style=\"margin-top:55px;text-align:center;font-size:30px\">Алгоритм ALL_REDUCE для транспьютерной матрицы</div>\n",
    "<strong><div style=\"margin-top:20px;text-align:center;font-size:30px\">Разработка отказоустойчивой версии программы для задачи Gauss</div>\n",
    "<strong><div style=\"margin-top:55px;text-align:center;font-size:30px\">ОТЧЕТ</div>\n",
    "<strong><div style=\"margin-top:25px;text-align:center;font-size:30px\">о выполненном задании</div>\n",
    "<div style=\"margin-top:55px;text-align:center;font-size:20px\">студентки 421 учебной группы факультета ВМК МГУ</div>\n",
    "<div style=\"margin-top:25px;text-align:center;font-size:20px\">Задорожной Юлии Андреевны</div>\n",
    "<div style=\"margin-top:100px;text-align:center;font-size:20px\">Москва, 2022 г.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1: Постановка задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1: Алгоритм ALL_REDUCE для транпьютерной матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется разработать и реализовать:\n",
    "\n",
    "В транспьютерной матрице размером 5*5, в каждом узле которой находится один процесс,\n",
    "необходимо выполнить операцию нахождения максимума среди 25 чисел (каждый процесс\n",
    "имеет свое число). Найденное максимальное значение должно быть получено на каждом про-\n",
    "цессе.\n",
    "\n",
    "Реализовать программу, моделирующую выполнение операции MPI_ALLREDUCE на транспью-\n",
    "терной матрице при помощи пересылок MPI типа точка-точка.\n",
    "\n",
    "Оценить сколько времени потребуется для выполнения операции MPI_ALLREDUCE, если все про-\n",
    "цессы выдали эту операцию редукции одновременно. Время старта равно 100, время передачи\n",
    "байта равно 1 (Ts=100,Tb=1). Процессорные операции, включая чтение из памяти и запись в\n",
    "память, считаются бесконечно быстрыми."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2: Разработка отказоустойчивой версии программы для задачи Gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доработать MPI-программу, реализованную в рамках курса “Суперкомпьютеры и параллельная обработка данных”. \n",
    "Добавить контрольные точки для продолжения работы программы в случае сбоя. Реализовать один из 3-х сценариев работы после сбоя: \n",
    "\n",
    "a) продолжить работу программы только на “исправных” процессах; \n",
    "\n",
    "б) вместо процессов, вышедших из строя, создать новые MPI-процессы, которые необходимо использовать для продолжения расчетов; \n",
    "\n",
    "**в) при запуске программы на счет сразу запустить некоторое дополнительное количество MPI-процессов, которые использовать в случае сбоя.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2: Описание алгоритма.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1: Алгоритм ALL_REDUCE для транпьютерной матрицы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В транспьютерной матрице размером 5*5, в каждом узле которой находится один процесс, необходимо выполнить операцию нахождения максимума среди 25 чисел (каждый процесс имеет свое число). Найденное максимальное значение должно быть получено на процессе с координатами (0,0) и затем передано другим процессам.\n",
    "\n",
    "Минимальное время оценивается через минимальное расстояние между двумя самыми дальними процессами в матрице. \n",
    "\n",
    "Данную задачу разложим на две части: логика задачи MPI_Gather + MPI_Scatter\n",
    "\n",
    "Применим такой алгоритм:\n",
    "\n",
    "1) Поскольку передачи в транспьютерной матрице возможны только к соседним узлам, то будем передавать число каждого процесса снизу вверх, производя сразу операцию редукции (вычисление максимума). Посмотреть процесс передачи \"cнизу-вверху\" можно посмотреть ниже:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[jupyter](7_sem/Report/inp.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Теперь смотрим на процессы в верхней строчке: в этих процессах также происходит операция вычисление максимума с имеющимися у них числами (это нечетные цифры на рисунке, кроме 1), последовательная передача полученного числа в соседний узел (это четные цифры на рисунке), снова вычисление максимума... и так, пока не окажемся с максимальным числом среди 25 элементов транспьютерной матрицы на процессе (0, 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:center;\" src=\"/home/jzadorozhnaya/Supercomputers_msu/7_sem/Report/inp2.png\" width=\"55%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Теперь максимальное число среди всех 25 процессов лежит в узле (0, 0). Его необходимо ~~сообщить~~ передать всем остальным процессам.\n",
    "Сначала из процесса (0, 0) мы передаем, например, всем процессам, лежащим в нулевой строке (красная стрелка), а затем из нулевой строки передаем это число всем процессам, лежащим под нулевой строкой (черная стрелка). Буквально, это операция, обратная операции передачи значения в процесс (0, 0), только без операции редукции. \n",
    "\n",
    "Визуально это будет выглядеть так: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:center;\" src=\"/home/jzadorozhnaya/Supercomputers_msu/7_sem/Report/inp4.png\" width=\"55%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Данный алгоритм был реализован с помощью функций MPI_Isend и MPI_Recv. Получение топологии в виде транспьютерной матрицы произведено с помощью функции MPI_Cart_rank.\n",
    "\n",
    "Оценим время работы алгоритма. Если время старта равно 100, время передачи байта равно 1 (Ts=100,Tb=1), то время выполнения операции передачи в одну сторону рассчитывается следующим образом:\n",
    "\n",
    "```\n",
    "                                 time = num_steps · (Ts + n * Tb)\n",
    "```\n",
    "\n",
    "где n - размер передаваемого сообщения в байтах. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае сообщением является число, размер которого может быть равен, например, 4 байтам (integer).\n",
    "Таким образом, при n = 5, и при двух проходах (сначала передача в (0, 0), а затем такая же передача уже в обратную сторону):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664\n"
     ]
    }
   ],
   "source": [
    "def calculate_time(size, ts = 100, tb = 1, count = 4):\n",
    "    return (size-1) * 4 * (ts + tb * count)\n",
    "\n",
    "print(calculate_time(5, ts = 100, tb = 1, count = 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Суммарное время: 1664 mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2: Разработка отказоустойчивой версии программы для задачи Gauss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для реализации отказоустойчивой версии был выбран метод, который создает дополнительные процессы, чтобы в случае ошибки заменить ими\n",
    "“испорченные” процессы и продолжить вычисления тем же количеством процессов. Другими словами, в новой программе происходит расставлении контрольных точек и в случае ошибки осуществляется возврат к этим контрольным точкам, удаление \"испорченных\" процессов, создание новых и последующая синхронизация и вычисления с тем же количеством процессов.\n",
    "\n",
    "Для этого рассмотрим основные функции программы: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) ``` verbose_errhandler() ```\n",
    "\n",
    "Данная функция описывает реакцию процессов в случае сбоя. В результате\n",
    "сбоя каждый процесс должен обновить свою рабочую группу (удалить из неё\n",
    "мёртвый процесс с помощью MPIX_Comm_shrink) и после этого сделать loadData,\n",
    "чтобы иметь правильные данные на момент начала чекпоинта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ```loadData()```\n",
    "\n",
    "В случае сбоя, данные загружаются из файлов в память каждого процесса. Это сделано для того, чтобы никакой процесс не имел на каком-то шаге\n",
    "наполовину обновленную матрицу. Матрицы должны быть сброшены к предыдущему шагу. После загрузки процессы ждут друг друга с помощью MPI_Barrier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ```saveData()```\n",
    "\n",
    "Данная функция отвечает за запись данных в файлы. Так как все процессы имеют одинаковые данные, то записью занимается процесс с рангом 0.\n",
    "Остальные же процессы ждут завершения процесса записи с помощью MPI_Barrier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Организация ~~чекпоинта~~ контрольной точки: \n",
    "\n",
    "```\n",
    "    saveData();\n",
    "    ...\n",
    "    flag = true; //флаг для входа в цикл\n",
    "    while( flag || err_fl){\n",
    "        err_fl = false;\n",
    "        flag = false;\n",
    "        ...\n",
    "        if(err_fl == false){\n",
    "            MPI_BARRIER(comm)\n",
    "    }\n",
    "    saveData();\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае если в данном блоке возникает ошибка, то флаг err_fl будет true. Тогда блок будет выполнен ещё раз с данными, которые были на последнем чекпоинте (при последнем saveData). Если блок будет завершён успешно всеми процессами, то идёт обновление бинарного файл(checkpoint)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3: Способы запуска программы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1: Алгоритм ALL_REDUCE для транпьютерной матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код, прилагаемый в 6 части, необходимо запустить c помощью bash-script файла start.sh. \n",
    "\n",
    "Это можно сделать с помощью команды ./start.sh <количество процессов>\n",
    "\n",
    "Содержимое файла start.sh:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "    mpicc main.c -o test -lm\n",
    "    mpiexec -n $1 ./test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2: Разработка отказоустойчивой версии программы для задачи Gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала нужно запустить docker container. \n",
    "\n",
    "Директория Task_2 cодержит реализацию отказоустойчивой программы Gauss (main.c), Makefile, а также три скрипта, реализующие запуск докера,  сборку и запуск программы. Обязательно требуется проделать первую команду:\n",
    "\n",
    "`./start_docker.sh` - будет извлекать все необходимые библиотеки из среды\n",
    "\n",
    "Содержимое `start_docker.sh`:\n",
    "\n",
    "``` bash\n",
    "    ulfm_image=abouteiller/mpi-ft-ulfm\n",
    "    docker pull $ulfm_image\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`./build.sh` - сборка проекта\n",
    "\n",
    "Содержимое `build.sh`:\n",
    "\n",
    "``` bash\n",
    "    sudo docker run -v $PWD:/sandbox:Z abouteiller/mpi-ft-ulfm make\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`./qstart.sh` - начать тест с предварительно написанными параметрами, такими как номер базового процесса = 5, размер матрицы 10X10\n",
    "\n",
    "Содержимое `qstart.sh`:\n",
    "\n",
    "``` bash\n",
    "    sudo docker run -v $PWD:/sandbox:Z abouteiller/mpi-ft-ulfm mpirun --oversubscribe -mca btl tcp,self -np 5 a.out 10\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`./start.sh -np  \"num_proc\" a.out \"matrix_size(one param)\" \"number of additional proc, default = 2\"` - чтобы начать настраиваемый тест\n",
    "\n",
    "Содержимое `start.sh`:\n",
    "``` bash\n",
    "    sudo docker run -v $PWD:/sandbox:Z abouteiller/mpi-ft-ulfm mpirun --oversubscribe -mca btl tcp,self \"$@\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Содержимое `Makefile`:\n",
    "\n",
    "``` makefile\n",
    "\tlocal_build:\n",
    "\t\tmpicc  -g main.c\n",
    "\n",
    "\tclean:\n",
    "\t\trm -f ./*_res\n",
    "\t\trm -f sec\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`make local_build` - локальная сборка\n",
    "\n",
    "`make clean` - удаление генератов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 4: Примеры запуска и выводов программы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1: Алгоритм ALL_REDUCE для транпьютерной матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:center;\" src=\"/home/jzadorozhnaya/Supercomputers_msu/7_sem/Report/task1_ex.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 5: Выводы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 6: Приложение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1: Алгоритм ALL_REDUCE для транпьютерной матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main.c:\n",
    "\n",
    "``` c\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "\n",
    "#include <mpi.h>\n",
    "#include <unistd.h>\n",
    "\n",
    "MPI_Request perform_operation(int x, int y) {\n",
    "    return x > y ? x : y;\n",
    "}\n",
    "\n",
    "MPI_Request send_int(int x, int y, MPI_Comm comm, int *data) {\n",
    "    int target_rank;\n",
    "    int coords[2] = {x, y};\n",
    "    MPI_Cart_rank(comm, coords, &target_rank);\n",
    "\n",
    "    MPI_Request request;\n",
    "    MPI_Isend(data, 1, MPI_INT, target_rank,\n",
    "              0, MPI_COMM_WORLD, &request);\n",
    "    return request;\n",
    "}\n",
    "\n",
    "int receive_int(int x, int y, MPI_Comm comm) {\n",
    "    int target_rank;\n",
    "    int coords[2] = {x, y};\n",
    "    MPI_Cart_rank(comm, coords, &target_rank);\n",
    "\n",
    "    int data;\n",
    "    MPI_Recv(&data, 1, MPI_INT, target_rank,\n",
    "             MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
    "    return data;\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv) {\n",
    "    int matrix_size;\n",
    "\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &matrix_size);\n",
    "\n",
    "    matrix_size = (int) sqrt((double) matrix_size);\n",
    "\n",
    "    int rank, size;\n",
    "\n",
    "    int ndims = 2;\n",
    "\n",
    "    int n_size[2] = {matrix_size, matrix_size};\n",
    "    int periodic[2] = {0, 0};\n",
    "\n",
    "    MPI_Comm cart_comm;\n",
    "\n",
    "    MPI_Cart_create(MPI_COMM_WORLD, ndims, n_size, periodic, 1, &cart_comm);\n",
    "\n",
    "    MPI_Comm_rank(cart_comm, &rank);\n",
    "    MPI_Comm_size(cart_comm, &size);\n",
    "\n",
    "    srand(time(NULL) + rank);\n",
    "\n",
    "    int coords[2];\n",
    "    MPI_Cart_coords(cart_comm, rank, ndims, coords);\n",
    "\n",
    "    int my_number = rand() % 128;\n",
    "\n",
    "    printf(\"My number is %4d, my coords is <%2d, %2d>\\n\", my_number, coords[0], coords[1]);\n",
    "    sleep(1);\n",
    "\n",
    "    int number;\n",
    "    if (coords[0] == 0) {\n",
    "        number = receive_int(coords[0] + 1, coords[1], cart_comm);\n",
    "        my_number = perform_operation(my_number, number);\n",
    "        printf(\"Got %d, my coords is <%2d, %2d>\\n\", number, coords[0], coords[1]);\n",
    "\n",
    "\n",
    "        if (coords[1] + 1 != matrix_size) {\n",
    "            number = receive_int(coords[0], coords[1] + 1, cart_comm);\n",
    "            my_number = perform_operation(my_number, number);\n",
    "            printf(\"Got %d, my coords is <%2d, %2d>\\n\", number, coords[0], coords[1]);\n",
    "        }\n",
    "\n",
    "        if (coords[1] != 0) {\n",
    "            MPI_Request request;\n",
    "            request = send_int(coords[0], coords[1] - 1, cart_comm, &my_number);\n",
    "            MPI_Wait(&request, MPI_STATUS_IGNORE);\n",
    "        }\n",
    "    } else {\n",
    "        if (coords[0] + 1 != matrix_size) {\n",
    "            number = receive_int(coords[0] + 1, coords[1], cart_comm);\n",
    "            my_number = perform_operation(my_number, number);\n",
    "\n",
    "            printf(\"Got %d, my coords is <%2d, %2d>\\n\", number, coords[0], coords[1]);\n",
    "        }\n",
    "\n",
    "        MPI_Request request;\n",
    "        request = send_int(coords[0] - 1, coords[1], cart_comm, &my_number);\n",
    "        MPI_Wait(&request, MPI_STATUS_IGNORE);\n",
    "    }\n",
    "\n",
    "    sleep(1);\n",
    "\n",
    "    if (coords[0] == 0 && coords[1] == 0) {\n",
    "        printf(\"Total number is %d\\n\", my_number);\n",
    "    }\n",
    "\n",
    "\n",
    "    MPI_Barrier(cart_comm);\n",
    "    sleep(1);\n",
    "\n",
    "    if (coords[0] == 0) {\n",
    "        if (coords[1] != 0) {\n",
    "            my_number = receive_int(coords[0], coords[1] - 1, cart_comm);\n",
    "            printf(\"Got number, my coords is <%2d, %2d>\\n\", coords[0], coords[1]);\n",
    "        }\n",
    "\n",
    "        MPI_Request r1, r2;\n",
    "        if (coords[1] + 1 != matrix_size) {\n",
    "            r1 = send_int(coords[0], coords[1] + 1, cart_comm, &my_number);\n",
    "        }\n",
    "        r2 = send_int(coords[0] + 1, coords[1], cart_comm, &my_number);\n",
    "        if (coords[1] + 1 != matrix_size) {\n",
    "            MPI_Wait(&r1, MPI_STATUS_IGNORE);\n",
    "        }\n",
    "        MPI_Wait(&r2, MPI_STATUS_IGNORE);\n",
    "    } else {\n",
    "        my_number = receive_int(coords[0] - 1, coords[1], cart_comm);\n",
    "        printf(\"Got number, my coords is <%2d, %2d>\\n\", coords[0], coords[1]);\n",
    "        MPI_Request r1;\n",
    "        if (coords[0] + 1 != matrix_size) {\n",
    "            r1 = send_int(coords[0] + 1, coords[1], cart_comm, &my_number);\n",
    "            MPI_Wait(&r1, MPI_STATUS_IGNORE);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    MPI_Finalize();\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2: Разработка отказоустойчивой версии программы для задачи Gauss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main.c:\n",
    "\n",
    "``` c\n",
    "#include <math.h>\n",
    "#include <stdlib.h>\n",
    "#include <stdio.h>\n",
    "#include <string.h>\n",
    "//#include <stdio.h>\n",
    "#include <sys/time.h>\n",
    "#include <mpi.h>\n",
    "#include \"mpi-ext.h\"\n",
    "#include <signal.h>\n",
    "\n",
    "\n",
    "void prt1a(char *t1, double *v, int n, char *t2);\n",
    "\n",
    "void print_matrix(double *a);\n",
    "\n",
    "\n",
    "MPI_Comm main_comm = MPI_COMM_WORLD;\n",
    "int N ;\n",
    "double *A;\n",
    "#define A(i, j) A[(i) * (N + 1) + (j)]\n",
    "double *X;\n",
    "bool reverse_sub = false;\n",
    "bool err_fl = false;\n",
    "int proc_num, myrank;\n",
    "//int errs = 0;\n",
    "//bool was = false;\n",
    "\n",
    "int additional_procs = 2;\n",
    "\n",
    "//char** v;\n",
    "\n",
    "//bool trouble_barrier = false;\n",
    "\n",
    "\n",
    "static void saveData()\n",
    "{\n",
    "    if (myrank == 0) {\n",
    "        FILE* f = fopen(\"elim_save.bin\", \"wb\");\n",
    "        fwrite(&A[0], sizeof(double),  (N-1)*N, f);\n",
    "        fclose(f);\n",
    "\n",
    "        if (reverse_sub) {\n",
    "            FILE* f = fopen(\"rs_save.bin\", \"wb\");\n",
    "            fwrite(&X[0], sizeof(double),  N, f);\n",
    "            fclose(f);\n",
    "        }\n",
    "    }\n",
    "    //printf(\"here-\\n\");\n",
    "    //fflush(stdout);\n",
    "    //MPI_Barrier(main_comm);\n",
    "    MPI_Barrier(main_comm);\n",
    "}\n",
    "\n",
    "static void loadData()\n",
    "{\n",
    "\n",
    "    \n",
    "    //if(myrank < proc_num){\n",
    "        FILE* f = fopen(\"elim_save.bin\", \"rb\");\n",
    "        fread(&A[0], sizeof(double), (N-1)*N, f);\n",
    "        fclose(f);\n",
    "        if (reverse_sub) {\n",
    "            FILE* f = fopen(\"rs_save.bin\", \"wb\");\n",
    "            fwrite(&X[0], sizeof(double),  N, f);\n",
    "            fclose(f);\n",
    "        }\n",
    "    //}    \n",
    "    //printf(\"Proc %d\\n\", myrank);\n",
    "    //fflush(stdout);\n",
    "    MPI_Barrier(main_comm);\n",
    "}\n",
    "\n",
    "\n",
    "static void verbose_errhandler(MPI_Comm* pcomm, int* perr, ...)\n",
    "{\n",
    "    //errs++;\n",
    "    MPI_Comm comm = *pcomm;\n",
    "    int err = *perr;\n",
    "    char errstr[MPI_MAX_ERROR_STRING];\n",
    "    int i, rank, size, nf, len, eclass;\n",
    "    MPI_Group group_c, group_f;\n",
    "    int *ranks_gc, *ranks_gf;\n",
    "\n",
    "\n",
    "    MPI_Error_class(err, &eclass);\n",
    "    if( MPIX_ERR_PROC_FAILED != eclass ) {\n",
    "        printf(\"Rank %d / %d: Notified of error %s. %d found dead: { \",\n",
    "           rank, size, errstr, nf);\n",
    "        MPI_Abort(comm, err);// stops all procesees if some other err occured\n",
    "    }\n",
    "    MPI_Comm_rank(comm, &rank);\n",
    "    MPI_Comm_size(comm, &size);\n",
    "    //was = true;\n",
    "    MPIX_Comm_failure_ack(comm);\n",
    "    MPIX_Comm_failure_get_acked(comm, &group_f);\n",
    "    MPI_Group_size(group_f, &nf);\n",
    "    MPI_Error_string(err, errstr, &len);\n",
    "    // MPIX_Comm_revoke(comm);//some error occures if revoke is used\n",
    "\n",
    "\n",
    "    printf(\"Rank %d / %d: Notified of error %s. %d found dead: { \",\n",
    "           rank, size, errstr, nf);\n",
    "\n",
    "    ranks_gf = (int*)malloc(nf * sizeof(int));\n",
    "    ranks_gc = (int*)malloc(nf * sizeof(int));\n",
    "    MPI_Comm_group(comm, &group_c);\n",
    "    for(i = 0; i < nf; i++)\n",
    "        ranks_gf[i] = i;\n",
    "    MPI_Group_translate_ranks(group_f, nf, ranks_gf,\n",
    "                              group_c, ranks_gc);\n",
    "    for(i = 0; i < nf; i++)\n",
    "        printf(\"%d \", ranks_gc[i]);\n",
    "    printf(\"}\\n\");\n",
    "    additional_procs -= nf;\n",
    "    //MPIX_Comm_revoke(main_comm);\n",
    "    MPIX_Comm_shrink(comm, &main_comm);// leave out of communicator dead processes\n",
    "    MPI_Comm_rank(main_comm, &myrank);\n",
    "    MPI_Comm_size(main_comm, &proc_num);\n",
    "    \n",
    "    proc_num -= additional_procs;\n",
    "    loadData();\n",
    "    //fflush(stdout);\n",
    "    err_fl = true;\n",
    "    free(ranks_gc);\n",
    "    free(ranks_gf);\n",
    "    //printf(\"%d\\n\", myrank);\n",
    "    //fflush(stdout);\n",
    "    MPI_Barrier(main_comm);\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "    MPI_Init(&argc, &argv);\n",
    "    //* adding extra processes to calculate on the same number of processes if error occures*\n",
    "    \n",
    "    if(argc == 3){ //enable custum number of additional proc\n",
    "        additional_procs = atoi(argv[2]);\n",
    "    }\n",
    "    MPI_Comm parent_comm, intercom_comm;\n",
    "    MPI_Comm_get_parent(&parent_comm);\n",
    "    if (parent_comm == MPI_COMM_NULL) {\n",
    "        MPI_Comm_spawn(\"./a.out\", \n",
    "                argv + 1, \n",
    "                additional_procs, \n",
    "                MPI_INFO_NULL, 0, \n",
    "                main_comm, \n",
    "                &intercom_comm, \n",
    "                MPI_ERRCODES_IGNORE);\n",
    "    } else {\n",
    "        intercom_comm = parent_comm;\n",
    "        //printf(\"helll%d\", atoi(argv[1]));\n",
    "        fflush(stdout);\n",
    "\n",
    "    }\n",
    "    MPI_Intercomm_merge(intercom_comm, (parent_comm == MPI_COMM_NULL ? 0 : 1), &main_comm);\n",
    "\n",
    "    //*intializtion of some variables*\n",
    "    MPI_Comm_size(main_comm, &proc_num);\n",
    "    MPI_Comm_rank(main_comm, &myrank);\n",
    "    proc_num = proc_num - additional_procs;\n",
    "    fflush(stdout);\n",
    "    MPI_Errhandler errh;\n",
    "    MPI_Comm_create_errhandler(verbose_errhandler, &errh);\n",
    "    MPI_Comm_set_errhandler(main_comm, errh);//error handler setup completed\n",
    "    int i, j, k;\n",
    "    bool flag = false;\n",
    "    N = atoi(argv[1]);//matrix size\n",
    "\n",
    "    fflush(stdout);\n",
    "    /* create arrays */\n",
    "    A = (double *)malloc(N * (N + 1) * sizeof(double));\n",
    "    X = (double *)malloc(N * sizeof(double));\n",
    "    if (myrank == 0) printf(\"GAUSS %dx%d\\n----------------------------------\\n\", N, N);\n",
    "    srand(12345);\n",
    "    /* initialize array A*/\n",
    "    for (i = 0; i <= N - 1; i++)\n",
    "        for (j = 0; j <= N; j++)\n",
    "            if (i == j || j == N)\n",
    "                A(i, j) = 1.f;\n",
    "            else\n",
    "                A(i, j) = 0.f;\n",
    "\n",
    "    double time0 = MPI_Wtime();\n",
    "    saveData();\n",
    "    // if(!trouble_barrier){\n",
    "    // }else{\n",
    "    //     trouble_barrier = false;\n",
    "    // }\n",
    "\n",
    "    /* elimination */\n",
    "\n",
    "    \n",
    "    //err_fl = false;\n",
    "    if (myrank == 0){\n",
    "        MPI_Barrier(main_comm);\n",
    "        raise(SIGKILL);\n",
    "    }else{\n",
    "        MPI_Barrier(main_comm);\n",
    "    }\n",
    "    //bool was = false; \n",
    "    flag = true;\n",
    "    while (err_fl || flag) {\n",
    "        err_fl = false;\n",
    "        \n",
    "            for (i = 0; i < N - 1; i++)\n",
    "            {\n",
    "                //printf(\"myrank = %d\\n\", myrank);\n",
    "                MPI_Bcast(&A(i, i + 1), N - i, MPI_DOUBLE, i % proc_num, main_comm);\n",
    "                if(myrank >= proc_num){ continue;}\n",
    "                for (k = myrank; k <= N - 1; k += proc_num) {\n",
    "                    if (k < i + 1) {\n",
    "                        continue;\n",
    "                    }\n",
    "                    for (j = i + 1; j <= N; j++) {\n",
    "                        A(k, j) = A(k, j) - A(k, i) * A(i, j) / A(i, i);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        flag = false;\n",
    "        if (!err_fl)\n",
    "                //printf(\" %d HERE4!!!!1 , %d\\n\", myrank, err_fl);\n",
    "            MPI_Barrier(main_comm);\n",
    "\n",
    "    }\n",
    "    //printf(\" %d HERE4!!!!1 , %d\\n\", myrank, err_fl);\n",
    "\n",
    "    saveData();\n",
    "    //printf(\" %d HERE4!!!!1 , %d\\n\", myrank, err_fl);\n",
    "\n",
    "    \n",
    "    /* reverse substitution */\n",
    "    //printf(\"here2\\n\");\n",
    "    //err_fl = false;\n",
    "    flag = true;\n",
    "    while (err_fl || flag) {\n",
    "        err_fl = false;\n",
    "        X[N - 1] = A(N - 1, N) / A(N - 1, N - 1);\n",
    "        flag = false;\n",
    "        if (!err_fl)\n",
    "            MPI_Barrier(main_comm);\n",
    "        //err_fl = false;\n",
    "    }\n",
    "    saveData();\n",
    "    reverse_sub = true;\n",
    "\n",
    "    if (myrank == 0){\n",
    "        MPI_Barrier(main_comm);\n",
    "        raise(SIGKILL);\n",
    "    }else{\n",
    "        MPI_Barrier(main_comm);\n",
    "    }\n",
    "    //err_fl = false;\n",
    "    flag = true;\n",
    "    while (err_fl || flag) {\n",
    "        err_fl = false;  \n",
    "            for (j = N - 2; j >= 0; j--) {\n",
    "                if(myrank < proc_num){\n",
    "                    for (k = myrank; k <= j; k += proc_num){\n",
    "                        A(k, N) = A(k, N) - A(k, j + 1) * X[j + 1];\n",
    "                    }\n",
    "                }\n",
    "                //printf(\"!!\\n\");    \n",
    "                MPI_Bcast(&A(j, N), 1, MPI_DOUBLE, j % proc_num, main_comm);\n",
    "                //printf(\"!!!!\\n\");\n",
    "                X[j] = A(j, N) / A(j, j);\n",
    "                if(err_fl){\n",
    "                    break;\n",
    "                }\n",
    "            }\n",
    "        //MPI_Barrier(main_comm);\n",
    "        flag = false;\n",
    "        if (!err_fl)\n",
    "            MPI_Barrier(main_comm);\n",
    "      \n",
    "    }\n",
    "    //printf(\"!!!!!\");\n",
    "    saveData();\n",
    "    double time1 = MPI_Wtime();\n",
    "\n",
    "    if (myrank == 0) {\n",
    "        printf(\"Time in seconds=%gs\\n\", time1 - time0);\n",
    "        prt1a(\"X=(\", X, N > 9 ? 9 : N, \"...)\\n\");\n",
    "        printf(\"Final_proc_num - %d\\n\", proc_num );\n",
    "    }\n",
    "\n",
    "    free(A);\n",
    "    free(X);\n",
    "    \n",
    "    MPI_Barrier(main_comm);\n",
    "    MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "void prt1a(char *t1, double *v, int n, char *t2)\n",
    "{\n",
    "    int j;\n",
    "    printf(\"%s\", t1);\n",
    "    for (j = 0; j < n; j++)\n",
    "        printf(\"%.4g%s\", v[j], j % 10 == 9 ? \"\\n\" : \", \");\n",
    "    printf(\"%s\", t2);\n",
    "}\n",
    "\n",
    "void print_matrix(double* a) {\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        for (int j = 0; j < N + 1; j++)\n",
    "            printf(\"%lf \", A(i, j));\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "}\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
